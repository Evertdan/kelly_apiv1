Metadata-Version: 2.4
Name: kelly_api
Version: 0.1.0
Summary: Backend API para KellyBot usando FastAPI, RAG con Qdrant y LLMs.
Author-email: Tu Nombre / Equipo <tu.correo@example.com>
License: MIT
Keywords: fastapi,api,chatbot,rag,qdrant,vector database,embeddings,sentence-transformers,llm,deepseek,openai,mongodb,langchain
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: Spanish
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Internet :: WWW/HTTP
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: fastapi<0.112.0,>=0.109.0
Requires-Dist: uvicorn[standard]<0.30.0,>=0.25.0
Requires-Dist: pydantic-settings<3.0.0,>=2.0.0
Requires-Dist: qdrant-client<2.0.0,>=1.9.0
Requires-Dist: sentence-transformers<3.0.0,>=2.2.0
Requires-Dist: numpy<2.0.0,>=1.21.0
Requires-Dist: torch
Requires-Dist: openai<2.0.0,>=1.10.0
Requires-Dist: langchain-core<0.3.0,>=0.1.0
Requires-Dist: langchain-mongodb<0.2.0,>=0.1.0
Requires-Dist: langchain-text-splitters<0.3.0,>=0.2.0
Requires-Dist: pymongo<5.0.0,>=4.0.0
Requires-Dist: markdown<4.0,>=3.5
Provides-Extra: dev
Requires-Dist: pytest<9.0.0,>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov<6.0.0,>=4.0.0; extra == "dev"
Requires-Dist: pytest-mock<4.0.0,>=3.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: httpx<0.29.0,>=0.25.0; extra == "dev"
Requires-Dist: ruff<1.0.0,>=0.4.0; extra == "dev"
Requires-Dist: black<25.0.0,>=23.0.0; extra == "dev"
Requires-Dist: mypy<2.0.0,>=1.0.0; extra == "dev"
Requires-Dist: pre-commit<4.0.0,>=3.0.0; extra == "dev"
Provides-Extra: test
Requires-Dist: pytest<9.0.0,>=7.0.0; extra == "test"
Requires-Dist: pytest-cov<6.0.0,>=4.0.0; extra == "test"
Requires-Dist: pytest-mock<4.0.0,>=3.0.0; extra == "test"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "test"
Requires-Dist: httpx<0.29.0,>=0.25.0; extra == "test"
Dynamic: license-file

# 🤖 **Kelly API**  
**Backend para Chatbot con RAG (Retrieval-Augmented Generation)**  


## 📘 1. Introducción

### 🎯 **1.1. Propósito de la API (Backend para KellyBot)**

Kelly API es un **backend robusto y centralizado** diseñado para potenciar al asistente conversacional **KellyBot**.  
Construido sobre el moderno framework **FastAPI (Python)**, actúa como el **"cerebro" del chatbot**, recibiendo preguntas desde múltiples interfaces (como Telegram, apps web, etc.) y generando respuestas **inteligentes, coherentes y contextualizadas**.

💡 **¿Qué hace?**
- Procesa lenguaje natural.
- Recupera información relevante.
- Genera respuestas precisas y personalizadas.

### 🧠 **1.2. Funcionalidad Principal (Procesamiento RAG)**

El núcleo del sistema utiliza el enfoque **RAG (Retrieval-Augmented Generation)**, mejorando la precisión y actualización de las respuestas mediante una combinación de búsqueda + generación.

#### ⚙️ **Pasos del Pipeline RAG:**

1. 🔍 **(Opcional) Contexto Prioritario:**  
   Consulta rápida a un archivo local (`priority_context.json`) para preguntas frecuentes.
2. 🕓 **(Opcional) Historial de Conversación:**  
   Recuperación del historial del usuario desde **MongoDB**.
3. 📚 **Recuperación (Retrieval):**  
   - Se genera un embedding vectorial con `sentence-transformers`.
   - Se consulta la base de conocimiento en **Qdrant**.
4. ➕ **Aumentación (Augmented):**  
   Se combinan:  
   - La pregunta original  
   - El historial  
   - El contexto recuperado  
5. ✨ **Generación (Generation):**  
   Se envía todo esto a un **LLM** (como DeepSeek), con instrucciones personalizadas (estilo y tono de “Kely”) para crear una **respuesta empática, clara y útil**.

> ✅ Este proceso asegura que las respuestas sean **contextuales, basadas en datos reales y adaptadas al usuario final.**

### 🔗 **1.3. Relación con `kelly_soap` y `kelly_indexer`**

Kelly API **no trabaja sola**, forma parte de un ecosistema de tres componentes:

#### 🧾 `kelly_soap` – Extracción de conocimiento
Convierte documentos semiestructurados (`.txt`, tipo SOAP) en archivos JSON estructurados de formato Pregunta/Respuesta.

- Campos clave: `faq_id`, `categoria`, `texto_para_vectorizar`, etc.

#### 📦 `kelly_indexer` – Vectorización e indexado
- Toma los JSON de `kelly_soap`
- Genera embeddings con `sentence-transformers`
- Los guarda en la base **Qdrant** junto con metadatos.

➡️ **Kelly API luego consulta esta base Qdrant**, preparada y actualizada por `kelly_indexer`.

### 👥 **1.4. Público Objetivo**

#### 👨‍💻 **Desarrolladores**
- Implementan y mantienen la API.
- Desarrollan clientes (Telegram bot, web apps, etc.) que la consumen.

#### 👩‍💼 **Usuarios Finales**
- Contadores y personal administrativo de **Computo Contable Soft**.
- Con conocimientos tecnológicos variables.

🧑‍🏫 Por eso, **"Kely"** debe:
- Ser clara y empática.  
- Evitar jerga técnica innecesaria.  
- Guiar paso a paso.  

## 🏗️ 2. Arquitectura General

Esta sección describe la estructura principal de **Kelly API** y cómo sus componentes colaboran para procesar las consultas del usuario y generar respuestas inteligentes.

### 🧩 **2.1. Componentes Principales e Interacciones**

KellyBot tiene una arquitectura **modular y escalable**, diseñada para que cada parte tenga una responsabilidad clara.

#### 🔄 **Flujo de Interacción General:**

1. 🧑‍💻 **Cliente:**  
   - Bot de Telegram, interfaz web o móvil.  
   - Envía mensajes del usuario a la **Kelly API**.

2. 🚀 **Kelly API (FastAPI Backend):**  
   - Recibe peticiones HTTP (`POST /chat`).  
   - Orquesta todo el pipeline de respuesta.  
   - Asíncrona, rápida y escalable.

3. 🌐 **Servicios Externos y Bases de Datos:**

   - 🧠 **Qdrant (Vector DB):**  
     Base de conocimiento indexada con embeddings y metadatos.  
     → Alimentada por `kelly_indexer`.

   - 💬 **LLM API (ej. DeepSeek):**  
     Genera la respuesta final en lenguaje natural, usando el contexto proporcionado.

   - 🗃️ **MongoDB (Historial - Opcional):**  
     Guarda/retrieved historial de conversación por sesión.

4. 📦 **Proyectos Relacionados:**
   - `kelly_soap` → Extrae información y la convierte a JSON Q&A.  
   - `kelly_indexer` → Vectoriza y sube a Qdrant.

### 🔁 **2.2. Flujo de Procesamiento de Mensajes (RAG Pipeline)**

Cuando un cliente llama al endpoint `POST /api/v1/chat`, Kelly API sigue este flujo:

#### 📬 1. **Recepción y Validación**
- Se recibe un JSON con `message` y `session_id`.
- Se valida estructura + API Key.

#### 📌 2. **Contexto Prioritario (Opcional)**
- Se revisa `priority_context.json`.  
- Si hay coincidencia, se devuelve una respuesta directa.

#### 🧾 3. **Historial de Chat (Opcional)**
- Si se activa, se consulta MongoDB para obtener historial por `session_id`.

#### 🧠 4. **Embedding de Consulta**
- Se convierte el `message` en un **vector semántico** con Sentence Transformers.

#### 🧲 5. **Búsqueda en Qdrant**
- Se recuperan los fragmentos más relevantes usando el vector.  
- Se obtienen `top_k` resultados con `score` y `payload`.

#### 🧷 6. **Formateo de Contexto**
- Se extrae información útil de los resultados Qdrant + historial.  
- Se crea un bloque `contexto_formateado` optimizado para el LLM.

#### 🧱 7. **Construcción del Prompt Final**
- Se une:  
  🧭 Instrucciones del sistema + 🧵 Contexto + ❓ Pregunta del usuario.

#### 🤖 8. **Llamada al LLM**
- El prompt se envía a DeepSeek (u otro LLM configurado).

#### 🧹 9. **Post-Procesamiento de Respuesta**
- Se limpia la respuesta (remoción de markdown, emojis, ajustes de estilo).

#### 🗄️ 10. **Guardado en Historial (Opcional)**
- Se guarda pregunta + respuesta final en MongoDB por `session_id`.

#### 📤 11. **Construcción de la Respuesta Final**
- Se incluye:
  - ✅ Respuesta final (`answer`)  
  - 📚 Fuentes (`sources`) de Qdrant

#### 📨 12. **Respuesta al Cliente**
- Se devuelve la respuesta JSON validada por el schema `ChatResponse`.

### ⚙️ **2.3. Servicios Principales (`app/services/`)**

Los servicios están organizados de forma modular en `app/services/`. Cada uno tiene una responsabilidad específica:

| 🧩 Módulo                     | 📝 Descripción                                                                 |
|------------------------------|-------------------------------------------------------------------------------|
| `rag_pipeline.py`            | Orquestador principal del flujo RAG. Llama a los otros servicios.            |
| `priority_context_service.py`| Busca en FAQs locales (con caché y similitud).                              |
| `history_service.py`         | (Opcional) Maneja la conexión con MongoDB para guardar y leer historial.     |
| `embedding_service.py`       | Convierte textos a embeddings con Sentence Transformers.                     |
| `qdrant_service.py`          | Lógica para buscar documentos en Qdrant usando vectores.                     |
| `llm_service.py`             | Envia prompts y recibe respuestas desde la API del LLM (ej. DeepSeek).       |

## ✨ 3. Características Principales

**Kelly API** ha sido diseñada con un conjunto de funcionalidades modernas que garantizan rendimiento, flexibilidad y escalabilidad como backend para un chatbot inteligente.

### ⚡ **API RESTful con FastAPI (async)**
- ✅ Basada en **FastAPI**, un framework moderno y rápido.
- 🚀 Manejo eficiente de múltiples conexiones con `async`/`await`.
- 🔁 Estructura RESTful estandarizada para facilitar integración con clientes (Telegram, web, etc).
### 🧠 **Pipeline RAG Configurable**
- 🔍 Combina recuperación de información + generación de lenguaje natural.
- ⚙️ Parámetros como `RAG_TOP_K` o `RAG_MAX_CONTEXT_TOKENS` son personalizables desde `.env`.
- 🔄 Permite balancear rendimiento vs. profundidad del análisis.
### 🧲 **Búsqueda Vectorial en Qdrant**
- 🧬 Utiliza embeddings para búsquedas semánticas.
- 📦 Conexión con la base Qdrant (`QDRANT_COLLECTION_NAME`) vía `qdrant-client`.
- 🔎 Encuentra respuestas relevantes aunque no coincidan textualmente.
### 🤖 **Generación de Respuestas con LLM (DeepSeek)**
- 📡 Interacción vía API con modelos LLM (como DeepSeek, usando `openai`).
- 🧾 Se envía un prompt con contexto + historial + personalidad de “Kely”.
- 🗣️ El resultado: respuestas naturales, empáticas y basadas en información real.
### 📁 **Contexto Prioritario Local (Opcional)**
- ⚡ Revisa `data/priority_context.json` antes de ejecutar el pipeline RAG.
- 🧠 Ideal para preguntas frecuentes y respuestas instantáneas.
- 💸 Ahorra recursos del LLM en casos simples.
### 💬 **Historial de Conversación (Opcional, MongoDB)**
- 🧵 Guarda mensajes anteriores por sesión (`session_id`).
- 🗂️ Recupera historial usando `langchain-mongodb`.
- 🧠 Permite respuestas más contextualizadas y coherentes.
### 💡 **Embeddings en Tiempo Real (CPU/GPU)**
- 📐 Convierte preguntas en vectores semánticos usando `sentence-transformers`.
- ⚙️ Detecta automáticamente hardware disponible (`EMBEDDING_DEVICE='auto'`).
- 🧠 Acelera procesos con GPU si está disponible (CUDA).
### 🔐 **Autenticación con API Key (Bearer Token)**
- 🔒 Los endpoints están protegidos con autenticación por token.
- 🛡️ Se requiere enviar `Authorization: Bearer <token>` en las cabeceras.
- 🗝️ Clave definida en `.env` (`API_ACCESS_KEY`).
### ⚙️ **Configuración Centralizada (.env)**
- 📋 Parámetros operativos y secretos están gestionados fuera del código.
- ✅ Validación automática mediante `pydantic-settings`.
- 🧪 Permite múltiples entornos: desarrollo, staging, producción.
### 📑 **Documentación Automática (Swagger UI / ReDoc)**
- 🔍 Autogenerada por FastAPI + Pydantic.
- 🧭 Explorable desde `/api/v1/docs` (Swagger) y `/api/v1/redoc` (ReDoc).
- 🧪 Ideal para pruebas y debugging desde el navegador.
### 🧱 **Estructura Modular y Escalable**
- 🧩 Código organizado por módulos: servicios, endpoints, esquemas, config.
- 🔄 Facilita mantenimiento, testing y futuras extensiones.
- 💼 Compatible con prácticas de desarrollo profesional.
### 📝 **Logging Configurable**
- 📊 Soporta niveles de log (`DEBUG`, `INFO`, etc.) vía `.env`.
- 🧾 Logs opcionalmente redirigibles a archivo (`API_LOG_FILE`).
- 🛠️ Esencial para monitoreo y resolución de errores.
### 🧪 **Listo para Desarrollo y Producción**
- 💻 Modo `reload` en desarrollo con `uvicorn`.
- 🏭 Preparado para producción con **Gunicorn** + múltiples workers.
- 🧱 Compatible con entornos ASGI modernos (Docker, Kubernetes, etc.).

## 🧰 4. Pila Tecnológica

**Kelly API** se basa en una selección de herramientas modernas del ecosistema Python para ofrecer una solución robusta, rápida y escalable. A continuación, se detalla la pila utilizada:
### 🧩 **Frameworks Principales**
| 🔧 Herramienta        | 📝 Descripción |
|----------------------|----------------|
| **⚡ FastAPI**        | Framework web asincrónico de alto rendimiento. Validación automática con Pydantic y documentación autogenerada. |
| **🔌 Uvicorn**        | Servidor ASGI ligero para ejecutar FastAPI. Compatible con desarrollo (`reload`) y producción (vía Gunicorn). |
| **📐 Pydantic / Pydantic-Settings** | Validación de esquemas de datos y carga de configuración desde `.env` en `app/core/config.py`. |
### 🔍 **Motor de Recuperación Semántica (RAG)**
| 🧠 Componente            | 🔎 Rol clave en el pipeline |
|--------------------------|------------------------------|
| **📦 Qdrant-Client**      | Cliente oficial para conexión asíncrona a la base vectorial Qdrant. |
| **🧬 Sentence-Transformers** | Generación de embeddings a partir de preguntas. |
| **🔥 PyTorch (Torch)**     | Motor de deep learning para ejecutar `sentence-transformers`. Soporte para GPU (CUDA). |
| **📊 NumPy**              | Librería numérica para manejo de arrays de embeddings. |
### 🤖 **Interacción con LLM (Generación de Respuestas)**
| 🧠 Tecnología          | 🚀 Propósito |
|------------------------|--------------|
| **📡 OpenAI (DeepSeek compatible)** | Cliente para enviar prompts y recibir respuestas del LLM configurado. Usa `AsyncOpenAI`. |
| **🧱 Langchain-Core (opcional)** | Estructuras comunes como `BaseMessage` y `Document` usadas para compatibilidad entre servicios. |
### 🗂️ **Gestión de Historial (Opcional)**
| 🗃️ Tecnología                  | 💬 Descripción |
|------------------------------|----------------|
| **🧵 Langchain-MongoDB**       | Clase `MongoDBChatMessageHistory` para almacenar diálogos por sesión. |
| **🔌 Pymongo**                | Driver base para conexión MongoDB local o Atlas. Usado por `history_service.py`. |
### 🧾 **Procesamiento de Texto y Chunking (Opcional)**
| 🧠 Librería                    | ✂️ Función |
|-------------------------------|------------|
| **📚 Langchain-Text-Splitters** | Divide textos largos de Qdrant en fragmentos procesables para el LLM. Usado por `text_chunker.py`. |
### 🧪 **Testing y Desarrollo**
| 🧪 Herramienta        | 🧰 Uso específico |
|------------------------|------------------|
| **🌐 HTTPX**           | Cliente HTTP asíncrono para pruebas de endpoints (`tests/conftest.py`). |
| **🧪 Pytest**          | Framework principal para pruebas unitarias e integración. |
| **🔌 Plugins Pytest:** `pytest-asyncio`, `pytest-cov`, `pytest-mock` | Pruebas async, cobertura de código, mocks. |
### 🧹 **Calidad de Código**
| 🧼 Herramienta     | 🧾 Función |
|--------------------|------------|
| **⚡ Ruff**         | Linter rápido con reglas personalizables. |
| **🎨 Black**        | Formateador de código estilo uniforme. |
| **🔍 MyPy**         | Verificador estático de tipos para prevenir errores antes de runtime. |
Esta pila técnica ha sido elegida para garantizar que **Kelly API** sea:  
✅ Rápida  
✅ Mantenible  
✅ Extensible  
✅ Escalable  

## 🧾 5. Prerrequisitos

Antes de instalar y ejecutar **Kelly API**, asegúrate de tener el entorno adecuado, los servicios externos disponibles y las credenciales necesarias. Esta preparación es fundamental para un despliegue exitoso.
### 🖥️ **5.1. Software Requerido**

Asegúrate de tener el siguiente software en tu entorno de desarrollo (especialmente si usas **WSL2**):
| 📦 Software        | 📝 Descripción |
|--------------------|----------------|
| **🐍 Python 3.10+** | Requerido para características modernas del lenguaje y tipado estático. Verifica con `python --version`. |
| **🧪 Conda / Miniconda** | Recomendado para crear entornos virtuales aislados. Alternativa: `venv`. |
| **🔧 Git**          | Necesario para clonar el repositorio del proyecto. |
🔸 *Nota para usuarios de WSL:* Asegúrate de que tu sistema WSL2 tenga acceso a red y (si aplica) a GPU para procesamiento con CUDA.

### 🌐 **5.2. Servicios Externos y Datos**
La API depende de varios servicios externos. Estos deben estar activos y accesibles:

#### 📚 **Qdrant (Base Vectorial)**
- 🧠 Contiene los datos recuperables por embeddings.
- ⚠️ **Debe existir previamente** y estar poblada por `kelly_indexer`.
- 🔗 Configura: `QDRANT_URL`, `QDRANT_COLLECTION_NAME`.

#### 🤖 **API del LLM Generativo (ej. DeepSeek)**
- 📡 Necesitas una API Key válida y acceso al endpoint: `DEEPSEEK_BASE_URL`.

#### 🗄️ **MongoDB (Opcional - Historial)**
- 🗂️ Usado solo si activas la funcionalidad de historial.
- 🔑 Configura con `MONGO_URI` (cadena de conexión completa).

### 🔐 **5.3. Credenciales Necesarias**
Estas claves deben almacenarse de forma **segura** en tu archivo `.env`:
| 🔑 Variable              | 🧾 Descripción |
|--------------------------|----------------|
| **`API_ACCESS_KEY`**      | Clave secreta para acceder a tu API. Los clientes deben enviarla como `Authorization: Bearer <token>`. |
| **`DEEPSEEK_API_KEY`**    | Clave de acceso al modelo LLM (DeepSeek u otro). Obligatoria para la generación de respuestas. |
| **`QDRANT_API_KEY`**      | (Opcional) Requerida si usas Qdrant Cloud con autenticación. |
| **`MONGO_URI`**           | (Opcional) Cadena de conexión a tu base de datos MongoDB. |
📌 **Importante:** Estas variables son sensibles. No las compartas públicamente y mantenlas fuera del control de versiones (usa `.gitignore` para excluir tu `.env`).

## 🛠️ 6. Instalación

Sigue estos pasos para configurar y ejecutar **Kelly API** localmente. Se asume que ya tienes un entorno tipo **Linux** (ej. **WSL2**) y que cumpliste los prerrequisitos.

### 🔄 **6.1. Clonar el Repositorio**
1. Abre tu terminal.
2. Navega al directorio donde quieras clonar el proyecto.
3. Ejecuta:
```bash
git clone <URL_DEL_REPOSITORIO_KELLY_API>
cd kelly_api
```
📁 Este directorio será la raíz para todos los comandos siguientes.

### 🐍 **6.2. Crear y Activar Entorno Conda**
Crea un entorno aislado para evitar conflictos de dependencias:
```bash
conda create --name kelly_api_env python=3.10 -y
conda activate kelly_api_env
```

🔔 Verás el prompt cambiar a `(kelly_api_env)`.  
🔁 *Recuerda activarlo cada vez que trabajes en el proyecto.*

### 📦 **6.3. Instalar Dependencias del Proyecto**
Desde la raíz del proyecto, instala las dependencias principales, de desarrollo y de pruebas:
```bash
pip install -e .[dev,test]
```
📌 Esto instalará automáticamente:
- Dependencias de runtime
- Herramientas de testing (`pytest`, `httpx`)
- Linters y formatters (`ruff`, `black`)
- Soporte async (`pytest-asyncio`, etc.)

### ⚡ **6.4. (Opcional) Instalar PyTorch con CUDA para GPU**
Si cuentas con una **GPU NVIDIA** + **CUDA en WSL2**, puedes acelerar la generación de embeddings:
1. Ve a 👉 [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)
2. Selecciona:  
   - **Stable**  
   - **Linux**  
   - **Pip o Conda**  
   - **CUDA** según tu instalación (ej. CUDA 12.1)
3. Copia y ejecuta el comando sugerido en tu terminal:
```bash
# ⚠️ Solo ejemplo. Usa el comando actualizado desde el sitio oficial
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```
🏁 Esto instalará una versión de **PyTorch con soporte GPU**.
> 💡 Si no tienes GPU o prefieres no usar CUDA, PyTorch usará CPU automáticamente.
✅ Con esto ya tendrás:
- El código del proyecto
- Un entorno virtual activo (`kelly_api_env`)
- Todas las librerías instaladas
- (Opcionalmente) PyTorch optimizado con GPU
🟢 El siguiente paso es configurar el archivo `.env` para conectar los servicios externos y establecer las credenciales.

## ⚙️ 7. Configuración (`.env`)
**Kelly API** utiliza un archivo `.env` para gestionar toda su configuración sensible y dependiente del entorno. Esto permite separar el código fuente de los secretos y adaptar la aplicación fácilmente a distintos entornos (dev, staging, producción).

### 📁 **7.1. Crear el archivo `.env` (desde `.env.sample`)**
1. Copia la plantilla:
```bash
cp .env.sample .env
```
2. Abre `.env` en tu editor favorito:
```bash
nano .env
```
3. Reemplaza los valores de ejemplo con tus datos reales.  
   🔐 ¡No compartas este archivo!

### 🧾 **7.2. Variables de Entorno (Explicadas)**
#### 🖥️ **Servidor API**
| Variable         | Descripción |
|------------------|-------------|
| `API_HOST`       | Dirección IP (ej: `0.0.0.0`, `127.0.0.1`) |
| `API_PORT`       | Puerto donde escucha la API (default: `8000`) |
| `LOG_LEVEL`      | Nivel de logging (`DEBUG`, `INFO`, etc.) |
| `API_LOG_FILE`   | (Opcional) Ruta para guardar logs |
| `API_RELOAD`     | `true/false` para recarga automática (dev only) |
#### 🔐 **Seguridad de la API**
| Variable           | Descripción |
|--------------------|-------------|
| `API_ACCESS_KEY`   | ✅ **Obligatoria.** Clave que los clientes deben usar (`Bearer <token>`) |
#### 🤖 **LLM Generativo (DeepSeek)**
| Variable              | Descripción |
|------------------------|-------------|
| `DEEPSEEK_API_KEY`     | ✅ Clave API del proveedor LLM |
| `DEEPSEEK_BASE_URL`    | URL del endpoint (default: DeepSeek oficial) |
| `DEEPSEEK_MODEL_NAME`  | Nombre del modelo (ej: `deepseek-chat`) |
| `LLM_REQUEST_TIMEOUT`  | Tiempo máximo de espera por respuesta (default: `120.0`) |
#### 📚 **Qdrant (Base Vectorial)**
| Variable               | Descripción |
|------------------------|-------------|
| `QDRANT_URL`           | ✅ URL completa de tu instancia Qdrant |
| `QDRANT_API_KEY`       | (Opcional) Clave si usas Qdrant Cloud |
| `QDRANT_COLLECTION_NAME` | Nombre de la colección usada por `kelly_indexer` |
| `DISTANCE_METRIC`      | Métrica usada (`Cosine`, `Dot`, `Euclid`) |
#### 🧬 **Modelo de Embeddings**
| Variable              | Descripción |
|------------------------|-------------|
| `EMBEDDING_MODEL_NAME` | Modelo de `sentence-transformers` (ej: `intfloat/multilingual-e5-base`) |
| `VECTOR_DIMENSION`     | Dimensión del vector (ej: `768`) |
| `EMBEDDING_DEVICE`     | `auto`, `cuda` o `cpu` |
#### 🗃️ **MongoDB (Historial - Opcional)**
| Variable                 | Descripción |
|--------------------------|-------------|
| `MONGO_URI`              | URI completa (con credenciales si aplica) |
| `MONGO_DATABASE_NAME`    | Default: `kellybot_chat` |
| `MONGO_COLLECTION_NAME`  | Default: `chat_histories` |
#### ⚡ **Contexto Prioritario (Opcional)**
| Variable                      | Descripción |
|-------------------------------|-------------|
| `PRIORITY_CONTEXT_FILE_PATH`  | Ruta al JSON de respuestas rápidas |
| `PRIORITY_SIMILARITY_THRESHOLD` | Umbral de similitud (default: `0.85`) |
#### 🧠 **Parámetros del Pipeline RAG**
| Variable                   | Descripción |
|----------------------------|-------------|
| `RAG_TOP_K`                | Número de documentos a recuperar (ej: `3`) |
| `RAG_MAX_CONTEXT_TOKENS`   | Límite de tokens para el prompt del LLM (ej: `3000`) |

### 🚫 **7.3. Seguridad: Ignorar `.env` con Git**
Asegúrate de que tu archivo `.env` **NO se suba nunca al repositorio**.  
Incluye esta línea en `.gitignore`:
```bash
.env
```
🔒 **Solo el archivo `.env.sample` debe estar en el repo.**  
Así tus secretos se mantienen privados y tus colaboradores tienen una guía de configuración.

## 🚀 8. Ejecución de la API
Una vez que hayas instalado el proyecto y configurado tu archivo `.env`, puedes iniciar el servidor de **Kelly API** usando **Uvicorn** o **Gunicorn**, dependiendo de si estás en desarrollo o producción.
🔔 Asegúrate de tener tu entorno **`kelly_api_env` activado** y de estar ubicado en la carpeta raíz del proyecto.

### 🧪 **8.1. Modo Desarrollo (Con Recarga Automática)**
Este modo es ideal para desarrollar y testear la API, ya que **reinicia automáticamente el servidor** al detectar cambios.
#### ▶️ Opción 1: Uvicorn directo (recomendado)
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```
📌 Detalles:
- `--reload`: Recarga automática al guardar cambios.
- `--host`: Acepta conexiones desde cualquier interfaz.
- `--port`: Puerto en el que correrá la API.
#### ▶️ Opción 2: Script personalizado
```bash
python scripts/run_api.py
```
Este método usa las variables del `.env` como `API_HOST`, `API_PORT`, y `API_RELOAD`.
🔧 Requiere que `API_RELOAD=true` esté definido en el archivo `.env` y gestionado en `config.py`.

### 🏭 **8.2. Modo Producción (Con Gunicorn)**
Para producción, utiliza **Gunicorn** con workers asincrónicos para mejorar rendimiento y escalabilidad.
#### 📥 Instala Gunicorn (si no lo tienes)
```bash
pip install gunicorn
```
#### ▶️ Ejecuta con múltiples workers:
```bash
gunicorn -k uvicorn.workers.UvicornWorker -w 4 -b 0.0.0.0:8000 app.main:app
```
📌 Parámetros explicados:
- `-k`: Worker especializado de Uvicorn (ASGI).
- `-w 4`: Número de workers (usa más si tienes más núcleos).
- `-b`: Dirección IP y puerto de escucha.
- `app.main:app`: Punto de entrada (FastAPI app).

> ⚙️ Recomendación: Combinar con `systemd`, `nginx` o Docker para despliegues completos.

### 🔍 **8.3. Verificación de Inicio**
Al ejecutar la API, deberías ver logs como:
```
INFO:     Uvicorn running on http://0.0.0.0:8000
INFO:     Started server process [xxxxx]
INFO:     --- Iniciando KellyBot API (Lifespan) ---
INFO:     Host: 0.0.0.0, Puerto: 8000, LogLevel: INFO
INFO:     --- KellyBot API Iniciada y Lista (Lifespan) ---
```
✅ Si no ves errores `ERROR` o `CRITICAL`, el arranque fue exitoso.  
🌐 Prueba la API en tu navegador:  
[http://localhost:8000/api/v1/docs](http://localhost:8000/api/v1/docs)

### 🛑 **8.4. Detener el Servidor**
Presiona `Ctrl + C` en la terminal para detener el servidor.  
🔁 Puede requerir presionarlo dos veces si hay tareas pendientes.



**9. Uso de la API**
Esta sección describe cómo los desarrolladores de aplicaciones cliente (como bots, interfaces web, etc.) pueden interactuar con la API KellyBot una vez que esté corriendo.

**9.1. Autenticación (Cabecera `Authorization: Bearer <API_ACCESS_KEY>`)**
La seguridad es primordial. Los endpoints principales de la API KellyBot, en particular el endpoint `/api/v1/chat`, están protegidos y requieren autenticación mediante una clave API. Los clientes que deseen utilizar estos endpoints deben incluir una cabecera HTTP `Authorization` en cada una de sus peticiones.
El formato requerido para esta cabecera sigue el estándar **Bearer Token**:
```
Authorization: Bearer <TU_API_ACCESS_KEY_REAL>
```
Donde `<TU_API_ACCESS_KEY_REAL>` debe ser reemplazado por la clave secreta que se configuró en la variable `API_ACCESS_KEY` dentro del archivo `.env` del servidor de la API KellyBot. Esta es la clave que el administrador de la API debe generar y compartir de forma segura con los desarrolladores de las aplicaciones cliente autorizadas.

Cualquier petición a un endpoint protegido que no incluya esta cabecera, o que incluya una clave inválida o con formato incorrecto, recibirá una respuesta de error `401 Unauthorized`.
**9.2. Endpoints Disponibles**
La API ofrece los siguientes puntos de entrada principales:
* **`POST /api/v1/chat`**
    * **Propósito:** Este es el endpoint central para la funcionalidad del chatbot. Recibe el mensaje del usuario y el identificador de su sesión, ejecuta todo el pipeline RAG (Retrieval-Augmented Generation) – incluyendo la consulta opcional a contexto prioritario e historial, la búsqueda semántica en Qdrant y la generación final de respuesta con el LLM (DeepSeek) – y devuelve la respuesta del asistente junto con las fuentes de información consultadas.
    * **Request Body (Cuerpo de la Petición):** Se espera un payload en formato JSON que cumpla con el schema `ChatRequest`. Debe contener obligatoriamente los siguientes campos:
        * `message` (string): La pregunta o texto enviado por el usuario. No debe estar vacío.
        * `session_id` (string): Un identificador único que representa la sesión de conversación actual del usuario. Es esencial para funcionalidades futuras como el historial.
        * *Ejemplo de JSON válido:*
            ```json
            {
              "message": "¿Cuáles son los requisitos de sistema para MiAdminXML?",
              "session_id": "userXYZ-session12345"
            }
            ```
    * **Response Body Exitoso (Código 200 OK):** Si la petición es válida y el procesamiento es exitoso, la API devuelve un payload JSON que cumple con el schema `ChatResponse`. Contiene los siguientes campos:
        * `answer` (string): La respuesta final generada por el LLM, ya post-procesada.
        * `sources` (lista de objetos): Una lista que contiene información sobre los documentos o FAQs recuperados de Qdrant que se usaron como contexto principal para generar la respuesta. Cada objeto en la lista sigue el schema `SourceInfo` e incluye:
            * `source_id` (string): El identificador único de la fuente (generalmente el `faq_id` original o el UUID del punto en Qdrant).
            * `score` (float, opcional): La puntuación de similitud devuelta por Qdrant (más alta indica mayor relevancia).
        * `session_id` (string): El mismo ID de sesión que se envió en la petición, devuelto para referencia.
        * *Ejemplo de JSON de respuesta exitosa:*
            ```json
            {
              "answer": "MiAdminXML requiere Windows 10 u 11 de 64 bits, 4 GB de RAM y conexión a internet. Se recomienda un procesador Core i3 o superior y disco SSD.",
              "sources": [
                {
                  "source_id": "SYS-REQ-XML-01_q0",
                  "score": 0.915
                }
              ],
              "session_id": "userXYZ-session12345"
            }
            ```
    * **Respuestas de Error Comunes:**
        * `401 Unauthorized`: La cabecera `Authorization` falta, está mal formada o la clave API (`API_ACCESS_KEY`) es incorrecta.
        * `422 Unprocessable Entity`: El cuerpo JSON de la petición es inválido. Falta el campo `message` o `session_id`, o no son del tipo esperado (string). El cuerpo de la respuesta del error contendrá detalles específicos sobre qué campo falló la validación.
        * `500 Internal Server Error`: Ocurrió un error inesperado en el servidor mientras se procesaba la petición (ej. fallo al conectar con Qdrant, error en la API del LLM, un bug en el código del pipeline RAG). La respuesta puede contener un mensaje genérico; se deben revisar los logs del servidor API para obtener el detalle técnico del error.
* **`GET /`**
    * **Propósito:** Es un endpoint raíz simple, útil para verificar rápidamente si la instancia de la API está en línea y respondiendo a peticiones HTTP básicas. A menudo se usa como un health check muy elemental.
    * **Response Body Exitoso (200 OK):** Devuelve un objeto JSON simple definido por el schema `StatusResponse`, indicando que la API está operativa.
        * *Ejemplo:* `{"status": "ok", "message": "KellyBot API (v1) está operativa."}`
* **`GET /health`**
    * **Propósito:** Similar al endpoint raíz, pero específicamente diseñado para sistemas de monitoreo automatizado (como probes de Kubernetes, balanceadores de carga, etc.). Verifica que la aplicación FastAPI esté saludable y pueda procesar peticiones. Por defecto, no aparece en la documentación pública de OpenAPI/Swagger.
    * **Response Body Exitoso (200 OK):** Devuelve un objeto JSON simple `StatusResponse`.
        * *Ejemplo:* `{"status": "ok", "message": "API healthy."}`
        * *Nota:* En futuras versiones, este endpoint podría incluir verificaciones más profundas (ej. conectividad con Qdrant y LLM) para dar un estado de salud más preciso.

**9.3. Acceso a la Documentación Interactiva (Swagger UI / ReDoc)**
Una gran ventaja de usar FastAPI es la generación automática de documentación interactiva basada en el estándar OpenAPI. Una vez que el servidor API esté corriendo (por defecto en `http://localhost:8000`), puedes acceder a estas interfaces desde tu navegador web:
* **Swagger UI:** Navega a `http://localhost:8000/api/v1/docs`. Aquí encontrarás una lista de todos los endpoints disponibles (excepto los marcados como `include_in_schema=False` como `/health`), podrás ver los schemas de petición y respuesta (`ChatRequest`, `ChatResponse`, etc.), y podrás **enviar peticiones de prueba** directamente desde la interfaz (recuerda configurar la autenticación Bearer Token usando el botón "Authorize" si pruebas endpoints protegidos como `/chat`).
* **ReDoc:** Navega a `http://localhost:8000/api/v1/redoc`. Ofrece una vista alternativa y más enfocada en la documentación de los mismos endpoints y schemas.
Estas herramientas son extremadamente útiles tanto para los desarrolladores que consumen la API como para los que la desarrollan y prueban.
¡Entendido! Aquí tienes la descripción detallada en prosa para la sección **Estructura del Proyecto** de tu `README.md`. Aunque un diagrama visual

## 🧱 10. Estructura del Proyecto

El proyecto `kelly_api` sigue una arquitectura modular clara, alineada con las **buenas prácticas de FastAPI**. Está diseñado para facilitar la **mantenibilidad, escalabilidad** y la colaboración entre equipos.

### 🗂️ Estructura de Carpetas
```
kelly_api/
├── .env                  ← Configuración sensible (NO subir)
├── .env.sample           ← Plantilla del archivo .env
├── .gitignore            ← Exclusiones para Git
├── pyproject.toml        ← Dependencias y config del proyecto
├── README.md             ← Documentación principal
├── LICENSE               ← Licencia del proyecto
├── app/                  ← Código fuente principal de la API
│   ├── main.py           ← Punto de entrada de FastAPI
│   │
│   ├── api/              ← Routers, endpoints y dependencias
│   │   ├── deps.py           ← Funciones compartidas (`Depends`)
│   │   └── v1/               ← Versión 1 de la API
│   │       ├── api.py            ← Router agregador
│   │       └── endpoints/
│   │           ├── chat.py        ← Endpoint POST /chat
│   │           └── status.py      ← Endpoints / y /health
│   │
│   ├── core/             ← Configuración y seguridad
│   │   ├── config.py         ← Clase Settings (.env)
│   │   └── security.py       ← Validación de API Key
│   │
│   ├── schemas/          ← Modelos Pydantic
│   │   ├── chat.py           ← `ChatRequest`, `ChatResponse`
│   │   └── status.py         ← `StatusResponse`
│   │
│   └── services/         ← Lógica de negocio y acceso a datos
│       ├── rag_pipeline.py       ← Orquestador RAG
│       ├── embedding_service.py  ← Embeddings con Transformers
│       ├── qdrant_service.py     ← Conexión a Qdrant
│       ├── llm_service.py        ← Conexión a LLM (DeepSeek)
│       ├── priority_context_service.py ← FAQs locales
│       └── history_service.py    ← Historial en MongoDB (opcional)
├── data/                 ← Archivos de datos locales
│   └── priority_context.json     ← Contexto prioritario FAQ
├── scripts/              ← Scripts auxiliares
│   └── run_api.py        ← Inicia el servidor Uvicorn
└── tests/                ← Pruebas automatizadas
    ├── conftest.py           ← Fixtures de prueba
    ├── api/                  ← Pruebas de endpoints
    ├── core/
    ├── schemas/
    └── services/
```

### 🧠 Descripción de Componentes
#### 📁 `app/`
- **`main.py`**: Inicializa la instancia de FastAPI y configura el ciclo de vida de la app.
- **`api/`**: Define y agrupa los endpoints. Soporta versionamiento (v1, v2...).
- **`core/`**: Configuración global, carga de `.env`, seguridad, etc.
- **`schemas/`**: Modelos Pydantic para validar y documentar requests/responses.
- **`services/`**: Lógica del negocio: embedding, RAG, acceso a Qdrant/LLM/Mongo.
#### 📁 `data/`
- Archivos JSON u otros recursos locales. Ejemplo: contexto FAQ prioritario.
#### 📁 `scripts/`
- Scripts CLI o de automatización. `run_api.py` arranca la API con lectura de `.env`.
#### 📁 `tests/`
- Organización paralela a `app/`, siguiendo la misma estructura para testeo modular.
#### 📄 `pyproject.toml`
- Gestión de dependencias (`[project.dependencies]`, `[dev]`, `[test]`)
- Configura herramientas como `ruff`, `pytest`, `black`.
#### 📄 `.env` / `.env.sample`
- `.env`: Variables reales de entorno (no subir a Git).
- `.env.sample`: Plantilla editable para configurar nuevos entornos.

### ✅ Ventajas de esta estructura
- 🔍 **Modular y clara**: Fácil de navegar.
- 🧪 **Lista para testing**: Soporte nativo para pruebas unitarias e integración.
- 🔁 **Escalable**: Soporta múltiples versiones de la API y nuevos servicios.
- 📦 **Listo para producción**: Compatible con Gunicorn, Docker, etc.

## 🧪 11. Pruebas Unitarias y de Integración

**Kelly API** incluye un sistema de pruebas automatizadas con **Pytest**, diseñado para garantizar la calidad del código, validar el comportamiento de los endpoints y asegurar la integridad del pipeline RAG ante cambios.

### ⚙️ **11.1. Configuración en `pyproject.toml`**
La configuración de Pytest se encuentra en el archivo `pyproject.toml`, bajo `[tool.pytest.ini_options]`.
#### 🔧 Opciones destacadas:
| Clave                         | Descripción |
|------------------------------|-------------|
| `minversion = "7.0"`         | Pytest 7 o superior. |
| `addopts`                    | Argumentos por defecto:<br>`-ra -q --cov=app --cov-report=term-missing` |
| `testpaths = ["tests"]`      | Directorio donde Pytest buscará pruebas. |
| `asyncio_mode = "auto"`      | Soporte automático para pruebas `async`. |

📌 **Cobertura activada por defecto** gracias a `pytest-cov`.

### ▶️ **11.2. Cómo Ejecutar las Pruebas**
#### 🧱 Paso a paso:
```bash
conda activate kelly_api_env         # Activa entorno
pip install -e .[dev,test]          # Asegura dependencias
cd kelly_api/                       # Ir al directorio raíz del proyecto
pytest                              # Ejecutar todas las pruebas
```
#### 🎯 Ejecución avanzada:
| Acción                          | Comando |
|--------------------------------|---------|
| Ejecutar un solo archivo       | `pytest tests/services/test_rag_pipeline.py` |
| Filtrar por nombre             | `pytest -k "test_chat_endpoint_success"` |
| Mostrar prints en terminal     | `pytest -s` |
| Parar tras primer fallo        | `pytest -x` |
| Reintentar últimas fallidas    | `pytest --lf` |

### 📈 **11.3. Cobertura de Código**
Después de ejecutar las pruebas, verás algo como:
```
Name                          Stmts   Miss  Cover   Missing
-----------------------------------------------------------
app/rag_pipeline.py             80     10    87%     34-40
app/embedding_service.py        50      4    92%     18, 29-31
...
-----------------------------------------------------------
TOTAL                          450     35    92%
```
- ✅ Alta cobertura = mayor confianza.
- 🧭 `term-missing` te muestra qué líneas no fueron cubiertas.

### 🧪 **11.4. Mocking de Servicios Externos**
Para pruebas efectivas, **no se debe depender de Qdrant, LLM o MongoDB en vivo**. Usa **mocking** con `pytest-mock`.
#### 🧰 Herramientas:
- `unittest.mock`
- `pytest-mock` (`mocker` fixture)
#### ✅ Ejemplos comunes:
| Contexto                         | Qué se mockea                                         |
|----------------------------------|--------------------------------------------------------|
| `test_chat.py` (endpoint)        | `rag_pipeline.generate_response`                      |
| `test_rag_pipeline.py` (servicio)| `embedding_service.embed_query` <br> `qdrant_service.search_documents` <br> `llm_service.call_llm` |
#### 🔧 Ejemplo básico:
```python
mocker.patch("app.services.rag_pipeline.generate_response", return_value=MockResponse)
```
💡 El mocking permite simular:
- Respuestas de éxito
- Errores de conexión
- Datos vacíos
- Comportamientos no determinísticos
### ✅ Beneficios del sistema de pruebas
- 🔄 Ejecutables en segundos, sin dependencias externas.
- 📉 Reduce riesgo de regresiones.
- 👨‍💻 Mejora el ciclo de desarrollo (test-driven).
- 🧪 Ideal para CI/CD y despliegues automáticos.

## 🧯 12. Solución de Problemas Comunes
Durante la configuración, ejecución o consumo de **Kelly API**, podrías encontrar errores. Aquí se listan los más frecuentes, junto con su causa probable y su solución recomendada.
> 📢 **Consejo general:** **Siempre revisa los logs de la terminal.** Es tu mejor herramienta para entender qué está fallando.
### 🚫 Errores al Iniciar la API
#### ❗ **ValidationError (al cargar `.env`)**
- **Síntoma:** 
  ```
  CRITICAL: Validation error for Settings
  QDRANT_URL: field required
  ```
- **Causa:** Falta una o más variables obligatorias en `.env`.
- **Solución:** Verifica que `.env` contenga:
  - `QDRANT_URL`
  - `DEEPSEEK_API_KEY`
  - `API_ACCESS_KEY`
  - Sin errores de sintaxis y sin líneas comentadas accidentalmente.
#### 🧩 **ImportError (al importar módulos)**
- **Síntoma:** Error del tipo:
  ```
  ImportError: cannot import name 'FastAPI'
  ```
- **Causa:** Dependencias no instaladas correctamente o problemas con el entorno.
- **Solución:**
  - Asegúrate de tener activado `conda activate kelly_api_env`.
  - Reinstala dependencias: `pip install -e .[dev,test]`.
  - Verifica existencia de `__init__.py` en todas las carpetas del paquete.

#### 🔌 **Address already in use (puerto ocupado)**
- **Síntoma:**
  ```
  OSError: [Errno 98] Address already in use
  ```
- **Causa:** Otro proceso (quizá otra instancia de la API) ya usa ese puerto.
- **Solución:**
  - Mata el proceso en uso: `lsof -i :8000` + `kill <PID>`.
  - O cambia `API_PORT` a otro valor (ej. `8001`) en `.env`.

#### ⚠️ **Error al cargar modelo de embeddings**
- **Síntoma:** Error desde `embedding_service.py` o `torch`, `transformers`, CUDA.
- **Causa:** Nombre de modelo mal escrito, falta internet, conflicto de versiones, problema con GPU.
- **Solución:**
  - Verifica `EMBEDDING_MODEL_NAME` en `.env`.
  - Ejecuta `pip list` y confirma instalación de `torch`, `sentence-transformers`.
  - Si usas GPU, revisa drivers y soporte CUDA.

### 🌐 Errores durante el uso de la API
#### 🔐 **401 Unauthorized**
- **Síntoma:**
  ```
  {"detail": "Not authenticated"}
  ```
- **Causa:** Cabecera `Authorization` ausente o con token incorrecto.
- **Solución:**
  - Asegúrate de enviar:
    ```
    Authorization: Bearer TU_API_ACCESS_KEY_REAL
    ```
  - Verifica que coincida exactamente con el valor en el servidor (`.env`).

#### 🧾 **422 Unprocessable Entity**
- **Síntoma:** Error al llamar a `POST /api/v1/chat`, con detalles sobre campos inválidos.
- **Causa:** JSON mal formado o campos faltantes (`message`, `session_id`).
- **Solución:**
  - Asegúrate de enviar:
    ```json
    {
      "message": "¿Qué hace MiAdminXML?",
      "session_id": "test-user-001"
    }
    ```
  - Usa Swagger (`/api/v1/docs`) para verificar el esquema correcto.

#### 🧨 **500 Internal Server Error**
- **Síntoma:**
  ```json
  {"detail": "Ocurrió un error interno..."}
  ```
- **Causa:** Error inesperado durante el procesamiento: fallos en Qdrant, DeepSeek, MongoDB o bugs internos.
- **Solución:**
  - Revisa logs en terminal.
  - Busca errores como:
    - `ConnectionRefusedError` → Qdrant
    - `AuthenticationError` → LLM
    - `KeyError` o `TypeError` → Bug interno


### 🧠 Respuestas del Chatbot que No Son Esperadas
#### 🤷 **Respuesta genérica o vacía**
- **Síntoma:** El bot responde:
  ```
  "Lo siento, no tengo esa información específica..."
  ```
- **Causa:**
  - No se encontró contexto útil en Qdrant.
  - Ocurrió un error controlado con el LLM.
- **Solución:**
  - Verifica que la colección de Qdrant tenga datos relevantes.
  - Aumenta `RAG_TOP_K` o ajusta `PRIORITY_SIMILARITY_THRESHOLD`.
  - Revisa logs para confirmar que el LLM respondió correctamente.

#### 📉 **Respuesta irrelevante o de baja calidad**
- **Causa común:**
  - Datos poco relevantes en Qdrant.
  - Embedding inadecuado para tu dominio.
  - Prompt del LLM mal calibrado.
  - Contexto truncado por `RAG_MAX_CONTEXT_TOKENS`.
- **Solución:**
  - Mejora la calidad de datos en `kelly_soap` y `kelly_indexer`.
  - Prueba otros modelos (`multilingual-e5-base`, `mpnet`, etc.).
  - Ajusta valores `.env`: `RAG_TOP_K`, `RAG_MAX_CONTEXT_TOKENS`.
  - Refina las instrucciones en el prompt del sistema.
🛟 **¿Aún con problemas?**
- Ejecuta con `LOG_LEVEL=DEBUG` para mayor detalle.
- Usa Swagger para validar requests.
- Si estás usando GPU, prueba forzar `EMBEDDING_DEVICE=cpu` para descartar errores de CUDA.

## 🧑‍💻 13. Guías para Desarrolladores
Esta sección está pensada para quienes contribuirán activamente al código de **Kelly API**. Aquí aprenderás cómo preparar tu entorno, cumplir con los estándares de calidad, ejecutar pruebas y participar en el proceso de desarrollo colaborativo.

### 🚀 **Primeros Pasos**
Antes de comenzar a programar, asegúrate de tener tu entorno listo:
1. **Clona el repositorio:**
   ```bash
   git clone <URL_DEL_REPO>
   cd kelly_api
   ```
2. **Crea y activa tu entorno Conda:**
   ```bash
   conda create -n kelly_api_env python=3.10 -y
   conda activate kelly_api_env
   ```
3. **Instala dependencias del proyecto:**
   ```bash
   pip install -e .[dev,test]
   ```
4. **Configura tu archivo `.env`:**
   - Copia desde `.env.sample`
   - Añade credenciales de Qdrant, DeepSeek, MongoDB, etc.
### 📏 **Estándares de Código y Herramientas de Calidad**
El proyecto utiliza herramientas configuradas desde `pyproject.toml`:
| Herramienta | Uso |
|-------------|-----|
| **Ruff**    | Linter + formateador rápido, incluye `isort` |
| **Black**   | Formateador adicional (opcional) |
| **MyPy**    | Verificación estática de tipos |
#### ✔️ Comandos útiles:
```bash
# Formatear el código
ruff format app/ tests/ scripts/
# Aplicar fixes y revisar errores de estilo
ruff check app/ tests/ scripts/ --fix
# Chequeo de tipos
mypy app/
```
👉 Corre estos comandos antes de hacer `commit` o enviar un PR.

### 🔁 **Proceso de Contribución (Flujo Sugerido)**
1. **Comunicación:** Discute nuevas features o cambios mayores abriendo un **Issue**.
2. **Branching:** Crea una rama a partir de `main`:
   ```bash
   git checkout -b feature/mi-mejora
   ```
3. **Desarrollo:** Implementa tus cambios.
4. **Testing:** Agrega pruebas en `tests/`. Corre:
   ```bash
   pytest --cov=app
   ```
5. **Calidad:** Ejecuta Ruff y MyPy como se mostró arriba.
6. **Commit y push:**
   ```bash
   git commit -m "feat: agrega autenticación JWT"
   git push origin feature/mi-mejora
   ```
7. **Pull Request:** Crea un PR desde tu rama hacia `main`. Incluye:
   - Descripción de los cambios
   - Captura de errores solucionados (si aplica)
   - Referencia al Issue (si corresponde)
8. **Revisión:** Colabora con el equipo para ajustar lo necesario hasta ser aprobado.
9. **Merge:** Será fusionado cuando todo esté validado. ✅

### 🐞 **Reporte de Errores y Sugerencias**
#### 📣 Reportar Bugs:
- Abre un **Issue** con:
  - Versión de Kelly API
  - Pasos para reproducir
  - Mensaje de error/log completo
  - Tu entorno (SO, Python, etc.)
#### 💡 Proponer Mejoras:
- Usa la etiqueta `enhancement` o `feature request`.
- Describe claramente:
  - Qué hace falta
  - Por qué es útil
  - Ejemplo de uso deseado
